# As more capable (but still small) models become available,
# pull requests are welcome at: https://github.com/xyproto/llm-manager/

# For chatting
chat=llama3.2:3b

# For code completion / tab autocompletion
code-completion=deepseek-coder:1.3b

# A small model, for quick tests
test=tinyllama:1b

# Text generation
text-generation=gemma2:2b

# Tool use and function calling
tool-use=llama3.2:3b

# For translating text (not single words, though)
translation=mixtral:8x7b

# Vision and image detection
vision=llava:7b
